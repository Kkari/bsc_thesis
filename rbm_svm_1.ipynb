{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from my_rbm import Rbm\n",
    "import six.moves.cPickle as pickle\n",
    "import sys\n",
    "from pandas import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin-1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def from_flat_to_3d(image):\n",
    "#     print(image.shape)\n",
    "    return np.dstack((image[0:1024].reshape(32,32),\n",
    "                       image[1024:2048].reshape(32,32),\n",
    "                       image[2048:3072].reshape(32,32)))\n",
    "\n",
    "cifar_test = unpickle('cifar-10-batches-py/test_batch')\n",
    "cifar_test['data'] = cifar_test['data'].astype(np.float32) / 255\n",
    "cifar_test['data_3d'] = np.array([from_flat_to_3d(image) for image in cifar_test['data']])\n",
    "\n",
    "cifar = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "for i in range(2, 6):\n",
    "    tmp = unpickle('cifar-10-batches-py/data_batch_' + str(i))\n",
    "    cifar['data'] = np.vstack((cifar['data'], tmp['data']))\n",
    "    cifar['labels'] = np.concatenate((cifar['labels'], tmp['labels']))\n",
    "\n",
    "cifar['data'] = cifar['data'].astype(np.float32) / 255\n",
    "cifar['data_3d'] = np.array([from_flat_to_3d(image) for image in cifar['data']])\n",
    "\n",
    "# cifar['data_bw'] = (cifar['data'][:,0:1024] + cifar['data'][:,1024:2048] + cifar['data'][:, 2048:3072]) / 3 \n",
    "# cifar_test['data_bw'] = (cifar_test['data'][:,0:1024] + cifar_test['data'][:,1024:2048] + cifar_test['data'][:, 2048:3072]) / 3 \n",
    "\n",
    "enc = OneHotEncoder()\n",
    "cifar['labels_oh'] = enc.fit_transform(cifar['labels'].reshape(-1, 1))\n",
    "cifar['labels_oh'] = cifar['labels_oh'].toarray()\n",
    "\n",
    "cifar_test['labels'] = np.array(cifar_test['labels'])\n",
    "cifar_test['labels_oh'] = enc.fit_transform(cifar_test['labels'].reshape(-1, 1))\n",
    "cifar_test['labels_oh'] = cifar_test['labels_oh'].toarray()\n",
    "\n",
    "# pca = PCA(whiten=True)\n",
    "# cifar['data_bw_whitened'] = pca.fit_transform(cifar['data_bw'])\n",
    "# cifar_test['data_bw_whitened'] = pca.fit_transform(cifar_test['data_bw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar_r = cifar['data'][:,0:1024]\n",
    "cifar_b = cifar['data'][:,1024:2048]\n",
    "cifar_g = cifar['data'][:,2048:]\n",
    "cifar_test_r = cifar_test['data'][:,0:1024]\n",
    "cifar_test_b = cifar_test['data'][:,1024:2048]\n",
    "cifar_test_g = cifar_test['data'][:,2048:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1024\n",
      "Number of classes: 10\n",
      "logit shape:  (?, 10)\n",
      "batch_labels shape:  (?, 10)\n",
      "epoch: 0\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.155813\n",
      "epoch: 1\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.140213\n",
      "epoch: 2\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.12607\n",
      "epoch: 3\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.113225\n",
      "epoch: 4\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.105468\n",
      "epoch: 5\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.102192\n",
      "epoch: 6\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0995677\n",
      "epoch: 7\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0978379\n",
      "epoch: 8\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0964798\n",
      "epoch: 9\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0963868\n",
      "Number of features: 1024\n",
      "Number of classes: 10\n",
      "logit shape:  (?, 10)\n",
      "batch_labels shape:  (?, 10)\n",
      "epoch: 0\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.153135\n",
      "epoch: 1\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.137762\n",
      "epoch: 2\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.123394\n",
      "epoch: 3\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.110532\n",
      "epoch: 4\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.102827\n",
      "epoch: 5\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0997739\n",
      "epoch: 6\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.097128\n",
      "epoch: 7\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0956335\n",
      "epoch: 8\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0946101\n",
      "epoch: 9\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0943428\n",
      "Number of features: 1024\n",
      "Number of classes: 10\n",
      "logit shape:  (?, 10)\n",
      "batch_labels shape:  (?, 10)\n",
      "epoch: 0\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.160046\n",
      "epoch: 1\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.127977\n",
      "epoch: 2\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.110982\n",
      "epoch: 3\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.104307\n",
      "epoch: 4\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.100906\n",
      "epoch: 5\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0992793\n",
      "epoch: 6\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0978612\n",
      "epoch: 7\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0967656\n",
      "epoch: 8\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0956539\n",
      "epoch: 9\n",
      "batch_number: 0\n",
      "batch_number: 1000\n",
      "batch_number: 2000\n",
      "batch_number: 3000\n",
      "batch_number: 4000\n",
      "rec_loss: 0.0950587\n"
     ]
    }
   ],
   "source": [
    "num_hidden = 261\n",
    "num_epochs=10\n",
    "rbm_r = Rbm(num_hidden=num_hidden, num_classes=10, num_features=1024, learning_rate=0.01)\n",
    "rbm_r.init_rbm()\n",
    "rbm_r.fit(cifar_r, cifar_test_r, num_epochs=num_epochs)\n",
    "\n",
    "num_hidden = 261\n",
    "num_epochs=10\n",
    "rbm_b = Rbm(num_hidden=num_hidden, num_classes=10, num_features=1024, learning_rate=0.01)\n",
    "rbm_b.init_rbm()\n",
    "rbm_b.fit(cifar_b, cifar_test_b, num_epochs=num_epochs)\n",
    "\n",
    "num_hidden = 261\n",
    "num_epochs=10\n",
    "rbm_g = Rbm(num_hidden=num_hidden, num_classes=10, num_features=1024, learning_rate=0.01)\n",
    "rbm_g.init_rbm()\n",
    "rbm_g.fit(cifar_g, cifar_test_g, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with: 0\n",
      "done with: 1000\n",
      "done with: 2000\n",
      "done with: 3000\n",
      "done with: 4000\n",
      "done with: 5000\n",
      "done with: 6000\n",
      "done with: 7000\n",
      "done with: 8000\n",
      "done with: 9000\n",
      "done with: 10000\n",
      "done with: 11000\n",
      "done with: 12000\n",
      "done with: 13000\n",
      "done with: 14000\n",
      "done with: 15000\n",
      "done with: 16000\n",
      "done with: 17000\n",
      "done with: 18000\n",
      "done with: 19000\n",
      "done with: 20000\n",
      "done with: 21000\n",
      "done with: 22000\n",
      "done with: 23000\n",
      "done with: 24000\n",
      "done with: 25000\n",
      "done with: 26000\n",
      "done with: 27000\n",
      "done with: 28000\n",
      "done with: 29000\n",
      "done with: 30000\n",
      "done with: 31000\n",
      "done with: 32000\n",
      "done with: 33000\n",
      "done with: 34000\n",
      "done with: 35000\n",
      "done with: 36000\n",
      "done with: 37000\n",
      "done with: 38000\n",
      "done with: 39000\n",
      "done with: 40000\n",
      "done with: 41000\n",
      "done with: 42000\n",
      "done with: 43000\n",
      "done with: 44000\n",
      "done with: 45000\n",
      "done with: 46000\n",
      "done with: 47000\n",
      "done with: 48000\n",
      "done with: 49000\n",
      "done with: 1\n",
      "done with: 1000\n",
      "done with: 1999\n",
      "done with: 2998\n",
      "done with: 3997\n",
      "done with: 4996\n",
      "done with: 5995\n",
      "done with: 6994\n",
      "done with: 7993\n",
      "done with: 8992\n",
      "done with: 9991\n",
      "done with: 0\n",
      "done with: 1000\n",
      "done with: 2000\n",
      "done with: 3000\n",
      "done with: 4000\n",
      "done with: 5000\n",
      "done with: 6000\n",
      "done with: 7000\n",
      "done with: 8000\n",
      "done with: 9000\n",
      "done with: 10000\n",
      "done with: 11000\n",
      "done with: 12000\n",
      "done with: 13000\n",
      "done with: 14000\n",
      "done with: 15000\n",
      "done with: 16000\n",
      "done with: 17000\n",
      "done with: 18000\n",
      "done with: 19000\n",
      "done with: 20000\n",
      "done with: 21000\n",
      "done with: 22000\n",
      "done with: 23000\n",
      "done with: 24000\n",
      "done with: 25000\n",
      "done with: 26000\n",
      "done with: 27000\n",
      "done with: 28000\n",
      "done with: 29000\n",
      "done with: 30000\n",
      "done with: 31000\n",
      "done with: 32000\n",
      "done with: 33000\n",
      "done with: 34000\n",
      "done with: 35000\n",
      "done with: 36000\n",
      "done with: 37000\n",
      "done with: 38000\n",
      "done with: 39000\n",
      "done with: 40000\n",
      "done with: 41000\n",
      "done with: 42000\n",
      "done with: 43000\n",
      "done with: 44000\n",
      "done with: 45000\n",
      "done with: 46000\n",
      "done with: 47000\n",
      "done with: 48000\n",
      "done with: 49000\n",
      "done with: 1\n",
      "done with: 1000\n",
      "done with: 1999\n",
      "done with: 2998\n",
      "done with: 3997\n",
      "done with: 4996\n",
      "done with: 5995\n",
      "done with: 6994\n",
      "done with: 7993\n",
      "done with: 8992\n",
      "done with: 9991\n",
      "done with: 0\n",
      "done with: 1000\n",
      "done with: 2000\n",
      "done with: 3000\n",
      "done with: 4000\n",
      "done with: 5000\n",
      "done with: 6000\n",
      "done with: 7000\n",
      "done with: 8000\n",
      "done with: 9000\n",
      "done with: 10000\n",
      "done with: 11000\n",
      "done with: 12000\n",
      "done with: 13000\n",
      "done with: 14000\n",
      "done with: 15000\n",
      "done with: 16000\n",
      "done with: 17000\n",
      "done with: 18000\n",
      "done with: 19000\n",
      "done with: 20000\n",
      "done with: 21000\n",
      "done with: 22000\n",
      "done with: 23000\n",
      "done with: 24000\n",
      "done with: 25000\n",
      "done with: 26000\n",
      "done with: 27000\n",
      "done with: 28000\n",
      "done with: 29000\n",
      "done with: 30000\n",
      "done with: 31000\n",
      "done with: 32000\n",
      "done with: 33000\n",
      "done with: 34000\n",
      "done with: 35000\n",
      "done with: 36000\n",
      "done with: 37000\n",
      "done with: 38000\n",
      "done with: 39000\n",
      "done with: 40000\n",
      "done with: 41000\n",
      "done with: 42000\n",
      "done with: 43000\n",
      "done with: 44000\n",
      "done with: 45000\n",
      "done with: 46000\n",
      "done with: 47000\n",
      "done with: 48000\n",
      "done with: 49000\n",
      "done with: 1\n",
      "done with: 1000\n",
      "done with: 1999\n",
      "done with: 2998\n",
      "done with: 3997\n",
      "done with: 4996\n",
      "done with: 5995\n",
      "done with: 6994\n",
      "done with: 7993\n",
      "done with: 8992\n",
      "done with: 9991\n"
     ]
    }
   ],
   "source": [
    "# Red\n",
    "last_output_r = np.empty((0, rbm_r.get_h_prob_out([cifar['data'][0, 0:1024]]).shape[1]))\n",
    "for i in range(cifar['data'].shape[0]):\n",
    "    last_output_r = np.vstack((last_output_r, rbm_r.get_h_prob_out([cifar['data'][i, 0:1024]])))\n",
    "    if i % 1000 == 0:\n",
    "        print('done with: %s' % i)\n",
    "        \n",
    "last_output_test_r = np.empty((0, rbm_r.get_h_prob_out([cifar_test['data'][0, 0:1024]]).shape[1]))\n",
    "for i in range(cifar_test['data'].shape[0]):\n",
    "    last_output_test_r = np.vstack((last_output_test_r, rbm_r.get_h_prob_out([cifar_test['data'][i, 0:1024]])))\n",
    "    if i % 999 == 0:\n",
    "        print('done with: %s' % (i + 1))\n",
    "\n",
    "# Blue\n",
    "last_output_b = np.empty((0, rbm_b.get_h_prob_out([cifar['data'][0, 1024:2048]]).shape[1]))\n",
    "for i in range(cifar['data'].shape[0]):\n",
    "    last_output_b = np.vstack((last_output_b, rbm_b.get_h_prob_out([cifar['data'][i, 1024:2048]])))\n",
    "    if i % 1000 == 0:\n",
    "        print('done with: %s' % i)\n",
    "        \n",
    "last_output_test_b = np.empty((0, rbm_b.get_h_prob_out([cifar_test['data'][0, 1024:2048]]).shape[1]))\n",
    "for i in range(cifar_test['data'].shape[0]):\n",
    "    last_output_test_b = np.vstack((last_output_test_b, rbm_b.get_h_prob_out([cifar_test['data'][i, 1024:2048]])))\n",
    "    if i % 999 == 0:\n",
    "        print('done with: %s' % (i + 1))\n",
    "        \n",
    "\n",
    "        \n",
    "# Green\n",
    "last_output_g = np.empty((0, rbm_g.get_h_prob_out([cifar['data'][0, 2048:]]).shape[1]))\n",
    "for i in range(cifar['data'].shape[0]):\n",
    "    last_output_g = np.vstack((last_output_g, rbm_g.get_h_prob_out([cifar['data'][i, 2048:]])))\n",
    "    if i % 1000 == 0:\n",
    "        print('done with: %s' % i)\n",
    "        \n",
    "last_output_test_g = np.empty((0, rbm_g.get_h_prob_out([cifar_test['data'][0, 2048:]]).shape[1]))\n",
    "for i in range(cifar_test['data'].shape[0]):\n",
    "    last_output_test_g = np.vstack((last_output_test_g, rbm_g.get_h_prob_out([cifar_test['data'][i, 2048:]])))\n",
    "    if i % 999 == 0:\n",
    "        print('done with: %s' % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked = np.hstack((last_output_r, last_output_g, last_output_b))\n",
    "stacked_test = np.hstack((last_output_test_r, last_output_test_g, last_output_test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 783)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape\n",
    "stacked_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovr', kernel='poly', degree=3, coef0=1.0)\n",
    "clf.fit(stacked, cifar['labels'])\n",
    "clf.score(stacked_test, cifar_test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
