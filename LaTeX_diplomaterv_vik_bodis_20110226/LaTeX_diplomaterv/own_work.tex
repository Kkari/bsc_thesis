%----------------------------------------------------------------------------
\chapter{Hálózatok impelmentálása és elemzése tensorflowban}
%----------------------------------------------------------------------------

A következõ részben szeretném bemutatni saját mukámat és mérési eredményeimet. Az elõzõ részben bemutatott hálózatfajtákból megvalósítottam számtalan példányt tensorflowban, és méréseket végeztem rajtuk az MNIST és a CIFAR-10 adathalmazon. A munkám célja az volt hogy leteszteljem a tensorflow lehetõségeit kísérleti hálózatok kifejlesztésére és monitorozására. A fejezet a következõ részekre tagolható:
\begin{enumerate}
\item A baseline metódusok bemutatása.
\item A fejlesztési környezet bemutatása.
\end{enumerate}

\section{A baseline osztályozók}
Természetesen nem lehet méréseket végezni baselineok nélkül, ezért a CIFAR-10 és az MNIST adathalmazon is lefuttattam két ismert, minden nehézség nélkül használható osztályozó algoritmust. Az egyik a Logisztikus regresszió volt, a másik pedig az SVM. Mindkettõ bemenetére közvetlen a kép pixeljeit tettem.

\section{A saját magam által kialakított fejlesztõkörnyezet}
A Tensorflow ökoszisztéma nagyon jó pontja a csúcsra járatott monitorozási lehetõségek, viszont nem triviális egy olyan struktúra kialakítása ahol az ember nagy hatékonysággal dolgozhat. Hosszas kísérletezés után a következõ munkafolyamatot találtam a legjobbnak:
\begin{itemize}
\item \emph{Gyors prototipizálás:} Erre a célra a Jupyter notebookokba írt TF-Slim magas szintû API-t találtam a legjobbnak, így nagyon gyorsan le lehet akármilyen ötletet tesztelni és kiértékelni.
\item \emph{Stabil modellek fejlesztése:} Ha egy modell túljutott a pár soros méreten, vagy tényleg egy nagyobb rendszer részeként szeretnénk használni akkor azt érdemesnek találtam osztályba foglalni, és a fejlesztéshez PyCharm IDE-t használni mert lényegesen gyorsabban lehet vele haladni komplex python kódnál mint a notebookokkal. 
\item \emph{A modellek kiértékelése:} A modellek kiértékelésére úgy gondolom hogy a Tensorflowval érkezõ Tensorboard a legalkalmasabb, mint majd látni fogja az olvasó a modelleim elemzésénél hogy ez az eszköz lehetõvé teszi komplex struktúrák elemzését egészen a tanulástól az igényelt rendszer erõforrásokig.
\item \emph{A modellbõl kinyert adatok részletes elemzése:} Erre a célra az klasszikus tudományos csomagok használatát találtam a legjobbnak jupyter notebookban alkalmazva, mert így egy helyen van a modell futtatása, a mérési eredmények és azt elemzõ kód.
\item \emph{Egzotikusabb modellek kivitelezése:} Ha az ember olyan modelleket szeretne kódolni amik túlnyúlnak a klasszikus elõrecsatolt struktúrákon akkor kénytelen lenyúlni a Tensorflow eredeti programozási absztrakciójához, mint ahogyan azt az RBM esetében látni fogjuk. Ez az alacsony API hatalmas szabadságot ad a programozónak, de iszonyatosan bõszavú (verbose).
\end{itemize}

\section{A saját implementációk bemutatása}
\subsection{A hálózatok monitorozása}
A Tensorflow kifejlett API-t kínál a hálózat paramétereinek követésére tanulás közben, de nem ment le automatikusan minden egyes lefutáskor minden változó értékét, mivel ez egy modern hálózatnál több millió értéket is jelenthet. A VGG konvoluciós háló például 140 millió paramétert tartalmaz. A hálózatról általánosságban a következõ értékeket mentettem le: minimum érték, maximum érték, közép érték és a standardizált szórásukat. hogy ezeket ne kelljen minden változóra kiadni, ezért a \listref{variableSummaries}-es függvényt alkalmaztam.

\begin{lstlisting}[frame=single,float=!ht,caption= A változók mentése label=listing:variableSummaries, mathescape=true]
def variable_summaries(name, var):
    """Attach a lot of summaries to a Tensor."""
    with tf.name_scope('summaries'):
        mean = tf.reduce_mean(var)
        tf.scalar_summary('mean/' + name, mean)
        with tf.name_scope('stddev'):
            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))
        tf.scalar_summary('sttdev/' + name, stddev)
        tf.scalar_summary('max/' + name, tf.reduce_max(var))
        tf.scalar_summary('min/' + name, tf.reduce_min(var))
        tf.histogram_summary(name, var)
\end{lstlisting}

\subsection{A logiszikus regresszió}
Az elsõ modell amit implementáltam Tensorflowban az a logisztikus regresszió volt. A célja az volt hogy összehasonlítsam a Tensorflow erõforrás igényét egy klasszikus python machine learning csomag, a Scikit-learn igényeivel. A struktúrát az <szám>~ábra szemlélteti. Egybõl látszódhat hogy az avatatlan szem számára a tensorboard eléggé nehezen értelmezhetõ lehet, ezért is szokták mondani hogy a tensorflownak a tanulási görbéje viszonylag nagy. Szerencse hogy lehet benne névtereket létrehozni hogy a gráfok könnyebben átláthatóak legyenek. Az egész tanulási gráfot a járulékos nodeokkal az <szám>~ábra szemlélteti.

\subsection{A többrétegû perceptron}
A többrétegû perceptronnal való kísérletezést a TF-Slim API nagyon megkönnyíti, minden nehézség nélkül a rétegeket egymás után tenni, ha pedig egyedi elemet szeretne az ember definiálni akkor arra is lehetõség van. Hasonló architektúrákat teszteltem az MNIST és a CIFAR-10 adathalmazon is, ami nagyon jól megfogta a két adathalmaz közötti különbséget. A \listref{MlpDef}-listázás egy ilyen háló definicióját szemlélteti.

\begin{lstlisting}[frame=single,float=!ht,caption= Egy MLP definiciója, label=listing:MlpDef, mathescape=true]
def fully_connected(batch_data, batch_labels):
    with slim.arg_scope([slim.fully_connected],
                      activation_fn=tf.nn.relu,
                      weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),
                      weights_regularizer=slim.l2_regularizer(0.0005)):
        # First Layer
        x = slim.fully_connected(batch_data, 400, scope='fc/fc_1')
        variable_summaries('fc/fc_1', x)
        
        # Second Layer
        x = slim.fully_connected(x, 1024, scope='fc/fc_2')
        variable_summaries('fc/fc_2', x)
        
        # Third Layer
        last_layer = slim.fully_connected(x, 10, activation_fn=None, scope='fc/fc_3')
        variable_summaries('fc/fc_3', x)
        predictions = tf.nn.softmax(x)
 
    	slim.losses.softmax_cross_entropy(last_layer, batch_labels)
	    total_loss = slim.losses.get_total_loss()
   	 	tf.scalar_summary('losses/total_loss', total_loss)
    
    	optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
        return optimizer, predictions
\end{lstlisting}

Mint látható nagyon könnyen állíthatóak a reguralizációs tagok, megadható több félet optimalizáló és hibafüggvény is, ami igazán könnyûvé tette a kísérletezést.

\subsection{Az RBM hálózat}
Mint mondtam a TF-Slim nagyon kényelmes volt addig amíg olyan struktúrákkal dolgoztam amik könnyen definiálhatóak. Viszont csak többrétegû perceptronok és konvoluciós hálózatokat lehet benne egyelõre alkotni. Az korlátozott boltzmann gép implementálásához le kellett mennem a Tensorflow alacsony szintû interfacéhez amiben a hálózat implementálása több mint egy hét volt. Viszont ezalatt értettem meg igazán hogy hogyan mûködik egyrészt a könyvtár, másrészt pedig az RBM-ek. 
Az RBM struktúra legtrükkösebb része a kontrasztív divergencia volt, mivel az egy valószínûségi döntés, de az egyes batchek futása közben nem tudok közvetlenül a gráfon belûl véletlen számokat generálni változtatható mennyiségben. Azért nem lehet egy adott méretben generálni, mert a batch méret változik, és minden számnak kellett generálni.
A megoldás amit alkalmaztam az az volt hogy numpy-ban legeneráltam minden tanításnál egy akkora mátrixot véletlen számokból mint amekkora a tanító halmazom volt. Majd a bináris 0-1 döntést a következõ képpen szimuláltam:
\begin{enumerate}
\item Kivontam a valósziníségi mátrixot a random számokból
\item Vettem az eljöjelét a keletkezett mátrixnak
\item Átvezettem egy relu rétegen, amitõl 0 és 1 közé normalizálódott.
\end{enumerate}

\paragraph{A tanítás} A tanítást kétféle képpen végeztem el, egyrészrõl definiáltam a szabad energia függvényt és a keretrendszerrel számoltattam ki a \eqref{rbmPFromEnergy} függvénybõl és különbözõ beépített optimalizátorokkal teszteltem, gradientdescenttel és Adamsoptimizerrel. Illetve a kísérletezés egy másik dimenziója az volt hogy egyes esetekben megengedtem az RBM felé kapcsolt regresszornak hogy az elõre megtanult súlyokat változtassa (ezt hívjuk fine-tuning-nak), más esetben pedig nem. Másrészt közvetlen kiszámoltam a gibbs sampling utáni értékekbõl \eqref{RbmWDirect}, \eqref{RbmCDirect} és \eqref{RbmBDirect} függvényeket és egyszerûen csak hozzáadtam õket a súlyvektorhoz. A \figref{RbmClosed}~ábra a hálózat madártávlati struktúráját szemlélteti. Könnyen kivehetõ hogy egy softmax réteg is hozzá van csatolva az RBM magjához, miután felügyelet nélkül tanítom az RBM-et az a réteg végzi az osztályzást. A \figref{rbmExpanded}~ábra pedig az RBM belsõ strukturját mutatja. Itt látszik igazán hogy a Tensorboard grafikonjai milyen kifonomult vizualizációt tesznek lehetõvé. A tanítás optimalizálását a \cite{rbmGuide} alapján végeztem.

\begin{figure}[!ht]
\centering
\includegraphics[width=100mm, keepaspectratio]{figures/rbmClosed}
\caption{} 
\label{fig:rbmClosed}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=100mm, keepaspectratio]{figures/rbmExpanded}
\caption{} 
\label{fig:rbmExpanded}
\end{figure}

\subsection{Hibrid modellek}
A kísérletezésünk során elkezdtünk olyan architektúrákkal foglalkozni ahol a kimenet nem a neurális hálózat része, mint például az RBM osztályozók általam tesztelt variánsánál, hanem a kimeneti aktivációk valószínûségi eloszlását adtam be mintánként egy SVM gépnek. Így hatalmas dimenzió csökkenést értünk el, pl 768-ról 1024-re, ami jelentõsen meggyorsította az SVM tanítását, anélkül hogy a nyers pixeladatokon tanított SVM-hez képest romlott volna a modell predikciós képessége. Az általam használt teszt gépen a CIFAR-10es adathalmaz nyers pixeljeit sajnos nem is tudtam megtanítani reális idõ alatt egy SVM-nek.

\subsection{A Konvoluciós modell}
